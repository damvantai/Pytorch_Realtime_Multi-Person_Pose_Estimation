{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "import pose_estimation\n",
    "import cv2\n",
    "from imutils.video import WebcamVideoStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "limbSeq = [[3,4], [4,5], [6,7], [7,8], [9,10], [10,11], [12,13], [13,14], [1,2], [2,9], [2,12], [2,3], [2,6], \\\n",
    "           [3,17],[6,18],[1,16],[1,15],[16,18],[15,17]]\n",
    "\n",
    "mapIdx = [[19,20],[21,22],[23,24],[25,26],[27,28],[29,30],[31,32],[33,34],[35,36],[37,38],[39,40], \\\n",
    "          [41,42],[43,44],[45,46],[47,48],[49,50],[51,52],[53,54],[55,56]]\n",
    "\n",
    "colors = [[255, 0, 0], [255, 85, 0], [255, 170, 0], [255, 255, 0], [170, 255, 0], [85, 255, 0], [0, 255, 0], \\\n",
    "          [0, 255, 85], [0, 255, 170], [0, 255, 255], [0, 170, 255], [0, 85, 255], [0, 0, 255], [85, 0, 255], \\\n",
    "          [170, 0, 255], [255, 0, 255], [255, 0, 170], [255, 0, 85]]\n",
    "\n",
    "boxsize = 368\n",
    "scale_search = [0.5, 1.0, 1.5, 2.0]\n",
    "stride = 8\n",
    "padValue = 0.\n",
    "thre_point = 0.15\n",
    "thre_line = 0.05\n",
    "stickwidth = 4\n",
    "\n",
    "def construct_model(path):\n",
    "\n",
    "    model = pose_estimation.PoseModel(num_point=19, num_vector=19)\n",
    "    # state_dict = torch.load(args.model)['state_dict']\n",
    "    state_dict = torch.load(path)\n",
    "    # from collections import OrderedDict\n",
    "    # new_state_dict = OrderedDict()\n",
    "    # for k, v in state_dict.items():\n",
    "    #     name = k[7:]\n",
    "    #     new_state_dict[name] = v\n",
    "    # state_dict = model.state_dict()\n",
    "    # state_dict.update(new_state_dict)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model = model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "def padRightDownCorner(img, stride, padValue):\n",
    "\n",
    "    h = img.shape[0]\n",
    "    w = img.shape[1]\n",
    "\n",
    "    pad = 4 * [None]\n",
    "    pad[0] = 0 # up\n",
    "    pad[1] = 0 # left\n",
    "    pad[2] = 0 if (h%stride==0) else stride - (h % stride) # down\n",
    "    pad[3] = 0 if (w%stride==0) else stride - (w % stride) # right\n",
    "\n",
    "    img_padded = img\n",
    "    pad_up = np.tile(img_padded[0:1,:,:]*0 + padValue, (pad[0], 1, 1))\n",
    "    img_padded = np.concatenate((pad_up, img_padded), axis=0)\n",
    "    pad_left = np.tile(img_padded[:,0:1,:]*0 + padValue, (1, pad[1], 1))\n",
    "    img_padded = np.concatenate((pad_left, img_padded), axis=1)\n",
    "    pad_down = np.tile(img_padded[-2:-1,:,:]*0 + padValue, (pad[2], 1, 1))\n",
    "    img_padded = np.concatenate((img_padded, pad_down), axis=0)\n",
    "    pad_right = np.tile(img_padded[:,-2:-1,:]*0 + padValue, (1, pad[3], 1))\n",
    "    img_padded = np.concatenate((img_padded, pad_right), axis=1)\n",
    "\n",
    "    return img_padded, pad\n",
    "\n",
    "def normalize(origin_img):\n",
    "\n",
    "\n",
    "    origin_img = np.array(origin_img, dtype=np.float32)\n",
    "    origin_img -= 128.0\n",
    "    origin_img /= 256.0\n",
    "\n",
    "    return origin_img\n",
    "\n",
    "def process(model, img):\n",
    "\n",
    "    origin_img = img\n",
    "    normed_img = normalize(origin_img)\n",
    "\n",
    "    height, width, _ = normed_img.shape\n",
    "\n",
    "    multiplier = [x * boxsize / height for x in scale_search]\n",
    "\n",
    "    heatmap_avg = np.zeros((height, width, 19)) # num_point\n",
    "    paf_avg = np.zeros((height, width, 38))     # num_vector\n",
    "\n",
    "    for m in range(len(multiplier)):\n",
    "        scale = multiplier[m]\n",
    "\n",
    "        # preprocess\n",
    "        imgToTest = cv2.resize(normed_img, (0, 0), fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "        imgToTest_padded, pad = padRightDownCorner(imgToTest, stride, padValue)\n",
    "\n",
    "        input_img = np.transpose(imgToTest_padded[:,:,:,np.newaxis], (3, 2, 0, 1)) # required shape (1, c, h, w)\n",
    "        mask = np.ones((1, 1, int(input_img.shape[2] / stride), int(input_img.shape[3] / stride)), dtype=np.float32)\n",
    "\n",
    "        input_var = torch.autograd.Variable(torch.from_numpy(input_img).cuda())\n",
    "        mask_var = torch.autograd.Variable(torch.from_numpy(mask).cuda())\n",
    "\n",
    "        # get the features\n",
    "        vec1, heat1, vec2, heat2, vec3, heat3, vec4, heat4, vec5, heat5, vec6, heat6 = model(input_var, mask_var)\n",
    "\n",
    "        # get the heatmap\n",
    "        heatmap = heat6.data.cpu().numpy()\n",
    "        heatmap = np.transpose(np.squeeze(heatmap), (1, 2, 0)) # (h, w, c)\n",
    "        heatmap = cv2.resize(heatmap, (0, 0), fx=stride, fy=stride, interpolation=cv2.INTER_CUBIC)\n",
    "        heatmap = heatmap[:imgToTest_padded.shape[0] - pad[2], :imgToTest_padded.shape[1] - pad[3], :]\n",
    "        heatmap = cv2.resize(heatmap, (width, height), interpolation=cv2.INTER_CUBIC)\n",
    "        heatmap_avg = heatmap_avg + heatmap / len(multiplier)\n",
    "\n",
    "        # get the paf\n",
    "        paf = vec6.data.cpu().numpy()\n",
    "        paf = np.transpose(np.squeeze(paf), (1, 2, 0)) # (h, w, c)\n",
    "        paf = cv2.resize(paf, (0, 0), fx=stride, fy=stride, interpolation=cv2.INTER_CUBIC)\n",
    "        paf = paf[:imgToTest_padded.shape[0] - pad[2], :imgToTest_padded.shape[1] - pad[3], :]\n",
    "        paf = cv2.resize(paf, (width, height), interpolation=cv2.INTER_CUBIC)\n",
    "        paf_avg = paf_avg + paf / len(multiplier)\n",
    "\n",
    "    all_peaks = []   # all of the possible points by classes.\n",
    "    peak_counter = 0\n",
    "\n",
    "    for part in range(1, 19):\n",
    "        map_ori = heatmap_avg[:, :, part]\n",
    "        map = gaussian_filter(map_ori, sigma=3)\n",
    "\n",
    "        map_left = np.zeros(map.shape)\n",
    "        map_left[:, 1:] = map[:, :-1]\n",
    "        map_right = np.zeros(map.shape)\n",
    "        map_right[:, :-1] = map[:, 1:]\n",
    "        map_up = np.zeros(map.shape)\n",
    "        map_up[1:, :] = map[:-1, :]\n",
    "        map_down = np.zeros(map.shape)\n",
    "        map_down[:-1, :] = map[1:, :]\n",
    "\n",
    "        # get the salient point and its score > thre_point\n",
    "        peaks_binary = np.logical_and.reduce(\n",
    "                (map >= map_left, map >= map_right, map >= map_up, map >= map_down, map > thre_point))\n",
    "        peaks = list(zip(np.nonzero(peaks_binary)[1], np.nonzero(peaks_binary)[0])) # (w, h)\n",
    "        \n",
    "        # a point format: (w, h, score, number)\n",
    "        peaks_with_score = [x + (map_ori[x[1], x[0]],) for x in peaks]\n",
    "        id = range(peak_counter, peak_counter + len(peaks))\n",
    "        peaks_with_score_and_id = [peaks_with_score[i] + (id[i], ) for i in range(len(id))]\n",
    "\n",
    "        all_peaks.append(peaks_with_score_and_id)\n",
    "        peak_counter += len(peaks)\n",
    "\n",
    "    connection_all = [] # save all of the possible lines by classes.\n",
    "    special_k = []      # save the lines, which haven't legal points.\n",
    "    mid_num = 10        # could adjust to accelerate (small) or improve accuracy(large).\n",
    "\n",
    "    for k in range(len(mapIdx)):\n",
    "\n",
    "        score_mid = paf_avg[:, :, [x - 19 for x in mapIdx[k]]]\n",
    "        candA = all_peaks[limbSeq[k][0] - 1]\n",
    "        candB = all_peaks[limbSeq[k][1] - 1]\n",
    "\n",
    "        lenA = len(candA)\n",
    "        lenB = len(candB)\n",
    "\n",
    "        if lenA != 0 and lenB != 0:\n",
    "            connection_candidate = []\n",
    "            for i in range(lenA):\n",
    "                for j in range(lenB):\n",
    "                    vec = np.subtract(candB[j][:2], candA[i][:2]) # the vector of BA\n",
    "                    norm = math.sqrt(vec[0] * vec[0] + vec[1] * vec[1])\n",
    "                    if norm == 0:\n",
    "                        continue\n",
    "                    vec = np.divide(vec, norm)\n",
    "\n",
    "                    startend = list(zip(np.linspace(candA[i][0], candB[j][0], num=mid_num), np.linspace(candA[i][1], candB[j][1], num=mid_num)))\n",
    "\n",
    "                    # get the vector between A and B.\n",
    "                    vec_x = np.array([score_mid[int(round(startend[I][1])), int(round(startend[I][0])), 0] for I in range(len(startend))])\n",
    "                    vec_y = np.array([score_mid[int(round(startend[I][1])), int(round(startend[I][0])), 1] for I in range(len(startend))])\n",
    "\n",
    "                    score_midpts = np.multiply(vec_x, vec[0]) + np.multiply(vec_y, vec[1])\n",
    "                    score_with_dist_prior = sum(score_midpts) / len(score_midpts) + min(0.5 * height / norm - 1, 0) # ???\n",
    "                    criterion1 = len(np.nonzero(score_midpts > thre_line)[0]) > 0.8 * len(score_midpts)\n",
    "                    criterion2 = score_with_dist_prior > 0\n",
    "                    if criterion1 and criterion2:\n",
    "                        connection_candidate.append([i, j, score_with_dist_prior, score_with_dist_prior + candA[i][2] + candB[j][2]])\n",
    "\n",
    "            # sort the possible line from large to small order.\n",
    "            connection_candidate = sorted(connection_candidate, key=lambda x: x[3], reverse=True) # different from openpose, I think there should be sorted by x[3]\n",
    "            connection = np.zeros((0, 5))\n",
    "\n",
    "            for c in range(len(connection_candidate)):\n",
    "                i, j, s = connection_candidate[c][0: 3]\n",
    "                if (i not in connection[:, 3] and j not in connection[:, 4]):\n",
    "                    # the number of A point, the number of B point, score, A point, B point\n",
    "                    connection = np.vstack([connection, [candA[i][3], candB[j][3], s, i, j]]) \n",
    "                    if len(connection) >= min(lenA, lenB):\n",
    "                        break\n",
    "            connection_all.append(connection)\n",
    "        else:\n",
    "            special_k.append(k)\n",
    "            connection_all.append([])\n",
    "\n",
    "    subset = -1 * np.ones((0, 20))\n",
    "    candidate = np.array([item for sublist in all_peaks for item in sublist])\n",
    "\n",
    "    for k in range(len(mapIdx)):\n",
    "        if k not in special_k:\n",
    "            partAs = connection_all[k][:, 0]\n",
    "            partBs = connection_all[k][:, 1]\n",
    "            indexA, indexB = np.array(limbSeq[k]) - 1\n",
    "\n",
    "            for i in range(len(connection_all[k])):\n",
    "                found = 0\n",
    "                flag = [False, False]\n",
    "                subset_idx = [-1, -1]\n",
    "                for j in range(len(subset)):\n",
    "                    # fix the bug, found == 2 and not joint will lead someone occur more than once.\n",
    "                    # if more than one, we choose the subset, which has a higher score.\n",
    "                    if subset[j][indexA] == partAs[i]:\n",
    "                        if flag[0] == False:\n",
    "                            flag[0] = found\n",
    "                            subset_idx[found] = j\n",
    "                            flag[0] = True\n",
    "                            found += 1\n",
    "                        else:\n",
    "                            ids = subset_idx[flag[0]]\n",
    "                            if subset[ids][-1] < subset[j][-1]:\n",
    "                                subset_idx[flag[0]] = j\n",
    "                    if subset[j][indexB] == partBs[i]:\n",
    "                        if flag[1] == False:\n",
    "                            flag[1] = found\n",
    "                            subset_idx[found] = j\n",
    "                            flag[1] = True\n",
    "                            found += 1\n",
    "                        else:\n",
    "                            ids = subset_idx[flag[1]]\n",
    "                            if subset[ids][-1] < subset[j][-1]:\n",
    "                                subset_idx[flag[1]] = j\n",
    "\n",
    "                if found == 1:\n",
    "                    j = subset_idx[0]\n",
    "                    if (subset[j][indexB] != partBs[i]):\n",
    "                        subset[j][indexB] = partBs[i]\n",
    "                        subset[j][-1] += 1\n",
    "                        subset[j][-2] += candidate[partBs[i].astype(int), 2] + connection_all[k][i][2]\n",
    "                elif found == 2: # if found equals to 2 and disjoint, merge them\n",
    "                    j1, j2 = subset_idx\n",
    "                    membership = ((subset[j1] >= 0).astype(int) + (subset[j2] >= 0).astype(int))[:-2]\n",
    "                    if len(np.nonzero(membership == 2)[0]) == 0: # merge\n",
    "                        subset[j1][:-2] += (subset[j2][:-2] + 1)\n",
    "                        subset[j1][-2:] += subset[j2][-2:]\n",
    "                        subset[j1][-2] += connection_all[k][i][2]\n",
    "                        subset = np.delete(subset, j2, 0)\n",
    "                    else: # as like found == 1\n",
    "                        subset[j1][indexB] = partBs[i]\n",
    "                        subset[j1][-1] += 1\n",
    "                        subset[j1][-2] += candidate[partBs[i].astype(int), 2] + connection_all[k][i][2]\n",
    "                elif not found and k < 17:\n",
    "                    row = -1 * np.ones(20)\n",
    "                    row[indexA] = partAs[i]\n",
    "                    row[indexB] = partBs[i]\n",
    "                    row[-1] = 2\n",
    "                    row[-2] = sum(candidate[connection_all[k][i, :2].astype(int), 2]) + connection_all[k][i][2]\n",
    "                    subset = np.vstack([subset, row])\n",
    "\n",
    "    # delete som rows of subset which has few parts occur\n",
    "    deleteIdx = []\n",
    "    for i in range(len(subset)):\n",
    "        if subset[i][-1] < 4 or subset[i][-2] / subset[i][-1] < 0.4:\n",
    "            deleteIdx.append(i)\n",
    "    subset = np.delete(subset, deleteIdx, axis=0)\n",
    "\n",
    "    # draw points\n",
    "    canvas = img\n",
    "    for i in range(18):\n",
    "        for j in range(len(all_peaks[i])):\n",
    "            cv2.circle(canvas, all_peaks[i][j][0:2], 4, colors[i], thickness=-1)\n",
    "\n",
    "    # draw lines\n",
    "    for i in range(17):\n",
    "        for n in range(len(subset)):\n",
    "            index = subset[n][np.array(limbSeq[i]) - 1]\n",
    "            if -1 in index:\n",
    "                continue\n",
    "            cur_canvas = canvas.copy()\n",
    "            Y = candidate[index.astype(int), 0]\n",
    "            X = candidate[index.astype(int), 1]\n",
    "            mX = np.mean(X)\n",
    "            mY = np.mean(Y)\n",
    "            length = ((X[0] - X[1]) ** 2 + (Y[0] - Y[1]) ** 2) ** 0.5\n",
    "            angle = math.degrees(math.atan2(X[0] - X[1], Y[0] - Y[1]))\n",
    "            polygon = cv2.ellipse2Poly((int(mY), int(mX)), (int(length / 2), stickwidth), int(angle), 0, 360, 1)\n",
    "            cv2.fillConvexPoly(cur_canvas, polygon, colors[i])\n",
    "            canvas = cv2.addWeighted(canvas, 0.4, cur_canvas, 0.6, 0)\n",
    "\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "import cv2\n",
    "import imutils\n",
    "class WebcamVideoStream:\n",
    "    def __init__(self, src=0):\n",
    "        self.stream = cv2.VideoCapture(src)\n",
    "        self.stream.set(3, 800)\n",
    "        self.stream.set(4, 600)\n",
    "        (self.grabbed, self.frame) = self.stream.read()\n",
    "        \n",
    "        self.stopped = False\n",
    "        \n",
    "    def start(self):\n",
    "        # Start the thread to read frames from the video stream\n",
    "        Thread(target=self.update, args=()).start()\n",
    "        return self\n",
    "    \n",
    "    def update(self):\n",
    "        while True:\n",
    "            if self.stopped:\n",
    "                return\n",
    "            \n",
    "            (self.grabbed, self.frame) = self.stream.read()\n",
    "            \n",
    "    def read(self):\n",
    "        return self.frame\n",
    "    \n",
    "    def stop(self):\n",
    "        self.stopped = True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'canvas' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b74584fd25d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo_capture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mcanvas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Video\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e5b7fdd9edd4>\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(model, origin_img)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0mcanvas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddWeighted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_canvas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcanvas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'canvas' referenced before assignment"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    \n",
    "    # Load model\n",
    "    model_path = \"/home/neosai/Documents/model/pose_human/pytorch/pose_model.pth\"\n",
    "    model = construct_model(model_path)\n",
    "    \n",
    "    video_capture = WebcamVideoStream(src=0).start()\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        frame = video_capture.read()\n",
    "        canvas = process(model, frame)\n",
    "        \n",
    "        cv2.imshow(\"Video\", frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
